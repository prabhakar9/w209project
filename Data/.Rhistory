simulate.study <- function(treatment.effect.size) {
po.control <- c(seq(from = 1, to = 20), seq(from = 51, to = 70))
po.treatment <- po.control + treatment.effect.size
treatment <- randomize()
outcomes <- po.treatment * treatment + po.control * (1 - treatment)
ate <- est.ate(outcomes, treatment)
distribution.under.sharp.null <- replicate(1000, est.ate(outcomes, randomize()))
return(mean(ate < distribution.under.sharp.null))
}
simulate.study(0) #p-value for no effect
p.values <- replicate(10000, simulate.study(0)) #distribution of p-
plot(density(p.values)) #uniform distribution
values
p.values
sum(p.values < 0)
sum(p.values < 1)
sum(p.values > 1)
sum(p.values > 1.0)
density(p.values)
sum(p.values<=)0
sum(p.values<=0)
sum(p.values<0)
sum(p.values<0.0001)
sum(p.values<-0.0001)
sum(p.values< -0.0001)
sum(p.values> 1.0001)
simulate.study <- function(treatment.effect.size) {
po.control <- c(seq(from = 1, to = 20), seq(from = 51, to = 70))
po.treatment <- po.control + treatment.effect.size
treatment <- randomize()
outcomes <- po.treatment * treatment + po.control * (1 - treatment)
ate <- est.ate(outcomes, treatment)
distribution.under.sharp.null <- replicate(1000, est.ate(outcomes, randomize()))
plot(density(distribution.under.sharp.null))
abline(v=ate)
return(mean(ate < distribution.under.sharp.null))
}
simulate.study(0) #p-value for no effect
simulate.study(0) #p-value for no effect
simulate.study(0) #p-value for no effect
simulate.study(0) #p-value for no effect
simulate.study(0) #p-value for no effect
simulate.study(0) #p-value for no effect
simulate.study(0) #p-value for no effect
simulate.study(0) #p-value for no effect
simulate.study(0) #p-value for no effect
simulate.study(0) #p-value for no effect
simulate.study(10) #p-value for no effect
simulate.study(10) #p-value for no effect
simulate.study(10) #p-value for no effect
simulate.study(10) #p-value for no effect
simulate.study(10) #p-value for no effect
simulate.study(0) #p-value for no effect
simulate.study(0) #p-value for no effect
simulate.study(1) #p-value for no effect
simulate.study(1) #p-value for no effect
simulate.study(1) #p-value for no effect
simulate.study(1) #p-value for no effect
simulate.study(3) #p-value for no effect
simulate.study(3) #p-value for no effect
simulate.study(3) #p-value for no effect
simulate.study(3) #p-value for no effect
simulate.study(3) #p-value for no effect
simulate.study(3) #p-value for no effect
simulate.study(3) #p-value for no effect
simulate.study(5) #p-value for no effect
simulate.study(5) #p-value for no effect
simulate.study(5) #p-value for no effect
simulate.study(5) #p-value for no effect
simulate.study(5) #p-value for no effect
simulate.study(5) #p-value for no effect
simulate.study(5) #p-value for no effect
simulate.study <- function(treatment.effect.size) {
po.control <- c(seq(from = 1, to = 20), seq(from = 51, to = 70))
po.treatment <- po.control + treatment.effect.size
treatment <- randomize()
outcomes <- po.treatment * treatment + po.control * (1 - treatment)
ate <- est.ate(outcomes, treatment)
distribution.under.sharp.null <- replicate(1000, est.ate(outcomes, randomize()))
#plot(density(distribution.under.sharp.null))
#abline(v=ate)
return(mean(ate < distribution.under.sharp.null))
}
p.values <- replicate(100, simulate.study(10))
p.values
p.values_0 <- replicate(10000, simulate.study(0)) #distribution of p-p.values_0plot(density(p.values_0)) # uniform distributionmean(p.values_0 < 0.05) # how often is p.value under 0.05 when there's no effect?p.values_10 <- replicate(1000, simulate.study(10))plot(density(p.values_10))mean(p.values_10 < 0.05) # somewhat likely to detect this effectp.values_20 <- replicate(1000, simulate.study(20))plot(density(p.values_20))mean(p.values_20 < 0.05) #very likely to detect this effect
p.values_0 <- replicate(10000, simulate.study(0)) #distribution of p-p.values_0plot(density(p.values_0)) # uniform distributionmean(p.values_0 < 0.05) # how often is p.value under 0.05 when there's no effect?p.values_10 <- replicate(1000, simulate.study(10))plot(density(p.values_10))mean(p.values_10 < 0.05) # somewhat likely to detect this effectp.values_20 <- replicate(1000, simulate.study(20))plot(density(p.values_20))mean(p.values_20 < 0.05) #very likely to detect this effect
p.values_10
estimate.in.confidence.interval <- function(){
true.effect <- 25
#Simulate outcomes
po.control <- c(seq(from = 1, to = 20), seq(from = 51, to = 70))
po.treatment <- po.control + true.effect
treatment <- randomize()
outcomes <- po.treatment * treatment + po.control*(1- treatment)
#Run regression
regression <- summary(lm(outcomes ~ treatment))
estimate <- regression$coefficients[2,1]
standard.error <- regression$coefficients[2,2]
lower.bound <- estimate - standard.error * 1.96
upper.bound <- estimate + standard.error * 1.96
#Is estimate in CI?
estimate.in.ci <- lower.bound < true.effect & upper.bound > true.effect
return(estimate.in.ci)
}
estimate.in.confidence.interval()
mean(replicate(10000, estimate.in.confidence.interval()))
group <- c(rep("Man",20),rep("Woman",20))
po.control <- c(seq(from = 1, to = 20), seq(from = 51, to = 70))
po.treatment <- po.control #no effect because potential outcomes in treatment are the same
po.control
po.treatment
# Function to randomly assign units to treatment and control
randomize <- function() c(sample(c(rep(0,10),rep(1,10))), sample(c(rep(0,10),rep(1,10))))
randomize()
randomize()
treatment <- randomize() # Conduct randomization for this experiment
treatment
# Realized outcomes - treatment outcome for those randomized to treatment and control outcome forthose randomized to control
outcomes <- po.treatment * treatment + po.control*(1-treatment)
outcomes
# Function to estimate the average treatment effect
est.ate <- function(outcome, treat) mean(outcome[treat==1]) - mean(outcome[treat==0])
ate <- est.ate(outcomes, treatment) # Compute the average treatment effect for this experiment
ate # You see a difference, despite there being no effect!
# How big is that difference likely to be on average?
# We can simulate this a few times to get a sense of how much our
treatment effect estimate would vary by chance
est.ate(outcomes, randomize())
est.ate(outcomes, randomize())
est.ate(outcomes, randomize())
# Do this 5,000 to get a sense of the distribution
distribution.under.sharp.null <- replicate(5000, est.ate(outcomes, randomize()))
est.ate(outcomes, randomize())
est.ate(outcomes, randomize())
est.ate(outcomes, randomize())
# Do this 5,000 to get a sense of the distribution
distribution.under.sharp.null <- replicate(5000, est.ate(outcomes, randomize()))
plot(density(distribution.under.sharp.null)) # It's likely we get big
differences by chance. This is a sampling distribution.
# How big was our observed difference?
plot(density(distribution.under.sharp.null))
plot(density(distribution.under.sharp.null))
abline(v=ate) # Pretty similar to one we'd get by chance
mean(ate <= distribution.under.sharp.null) # p-value
# Simulate an experiment with a large effect
# assignment and outcomes
po.treatment <- po.control + 25
po.control
po.treatment
treatment <- randomize()
outcomes <- po.treatment * treatment + po.control*(1-treatment)
outcomes
# Estimate ate
ate <- est.ate(outcomes, treatment)
ate
# What's the uncertainty?
distribution.under.sharp.null <- replicate(5000, est.ate(outcomes, randomize()))
plot(density(distribution.under.sharp.null))
abline(v=ate)
mean(ate < distribution.under.sharp.null) #p-value
distribution.under.sharp.null <- replicate(5000, est.ate(outcomes, randomize()))
plot(density(distribution.under.sharp.null))
abline(v=ate)
treatmet
treatment
outcomes
est.ate(outcomes, treatment)
ate <- est.ate(outcomes, treatment)
ate
abline(v=ate)
treatment <- randomize()
outcomes <- po.treatment * treatment + po.control*(1-treatment)
outcomes
# Estimate ate
ate <- est.ate(outcomes, treatment)
ate
po.treatment <- po.control
po.control
po.treatment
treatment <- randomize()
outcomes <- po.treatment * treatment + po.control*(1-treatment)
outcomes
# Estimate ate
ate <- est.ate(outcomes, treatment)
ate
# What's the uncertainty?
distribution.under.sharp.null <- replicate(5000, est.ate(outcomes, randomize()))
plot(density(distribution.under.sharp.null))
abline(v=ate)
treatment <- randomize()
outcomes <- po.treatment * treatment + po.control*(1-treatment)
po.treatment <- po.control + 10
po.control
po.treatment
treatment <- randomize()
outcomes <- po.treatment * treatment + po.control*(1-treatment)
outcomes
# Estimate ate
ate <- est.ate(outcomes, treatment)
ate
# What's the uncertainty?
distribution.under.sharp.null <- replicate(5000, est.ate(outcomes, randomize()))
plot(density(distribution.under.sharp.null))
abline(v=ate)
mean(ate < distribution.under.sharp.null) #p-value
ate
po.treatment <- po.control + 20
po.control
po.treatment
treatment <- randomize()
outcomes <- po.treatment * treatment + po.control*(1-treatment)
outcomes
# Estimate ate
ate <- est.ate(outcomes, treatment)
ate
# What's the uncertainty?
distribution.under.sharp.null <- replicate(5000, est.ate(outcomes, randomize()))
plot(density(distribution.under.sharp.null))
po.control
po.treatment
treatment <- randomize()
outcomes <- po.treatment * treatment + po.control*(1-treatment)
outcomes
# Estimate ate
ate <- est.ate(outcomes, treatment)
ate
# What's the uncertainty?
distribution.under.sharp.null <- replicate(5000, est.ate(outcomes, randomize()))
plot(density(distribution.under.sharp.null))
treatment
distribution.under.sharp.null <- replicate(5000, est.ate(outcomes, randomize()))
plot(density(distribution.under.sharp.null))
distribution.under.sharp.null <- replicate(5000, est.ate(outcomes, randomize()))
plot(density(distribution.under.sharp.null))
distribution.under.sharp.null <- replicate(5000, est.ate(outcomes, randomize()))
plot(density(distribution.under.sharp.null))
distribution.under.sharp.null <- replicate(5000, est.ate(outcomes, randomize()))
plot(density(distribution.under.sharp.null))
plot(density(distribution.under.sharp.null))
abline(v=ate)
distribution.under.sharp.null <- replicate(5000, est.ate(outcomes, randomize()))
plot(density(distribution.under.sharp.null))
abline(v=ate)
distribution.under.sharp.null <- replicate(5000, est.ate(outcomes, randomize()))
plot(density(distribution.under.sharp.null))
treatment <- randomize()
outcomes <- po.treatment * treatment + po.control*(1-treatment)
outcomes
# Estimate ate
ate <- est.ate(outcomes, treatment)
ate
# What's the uncertainty?
distribution.under.sharp.null <- replicate(5000, est.ate(outcomes, randomize()))
plot(density(distribution.under.sharp.null))
distribution.under.sharp.null <- replicate(5000, est.ate(outcomes, randomize()))
plot(density(distribution.under.sharp.null))
distribution.under.sharp.null <- replicate(5000, est.ate(outcomes, randomize()))
plot(density(distribution.under.sharp.null))
mean(ate < distribution.under.sharp.null) #p-value
simulate.study <- function(treatment.effect.size) {
po.control <- c(seq(from = 1, to = 20), seq(from = 51, to = 70))
po.treatment <- po.control + treatment.effect.size
treatment <- randomize()
outcomes <- po.treatment * treatment + po.control * (1 - treatment)
ate <- est.ate(outcomes, treatment)
distribution.under.sharp.null <- replicate(1000, est.ate(outcomes, randomize()))
# plot(density(distribution.under.sharp.null))
# abline(v=ate)
return(mean(ate < distribution.under.sharp.null))
}
simulate.study(0) #p-value for no effect
simulate.study(0) #p-value for no effect
simulate.study(0) #p-value for no effect
p.values_0 <- replicate(1000, simulate.study(0)) #distribution of p-values
p.values_0
plot(density(p.values_0)) # uniform distribution
mean(p.values_0 < 0.05) # how often is p.value under 0.05 when there's no effect?
p.values_10 <- replicate(1000, simulate.study(10))
plot(density(p.values_10))
mean(p.values_10 < 0.05) # somewhat likely to detect this effect
p.values_20 <- replicate(1000, simulate.study(20))
plot(density(p.values_20))
mean(p.values_20 < 0.05) #very likely to detect this effect
plot(density(p.values_10))
plot(density(p.values_20))
plot(density(p.values_20))
plot(density(p.values_10))
plot(density(p.values_20))
plot(density(p.values_10))
plot(density(p.values_20))
p.values_10
p.values_20
plot(density(p.values_10))
plot(density(p.values_20))
randomize <- function() sample(c(rep(0,20),rep(1,20)))
p.values_0 <- replicate(1000, simulate.study(0)) #distribution of p-values
plot(density(p.values_0)) # uniform distribution
mean(p.values_0 < 0.05) # how often is p.value under 0.05 when there's no effect?
p.values_10 <- replicate(1000, simulate.study(10))
plot(density(p.values_10))
mean(p.values_10 < 0.05) # somewhat likely to detect this effect
p.values_20 <- replicate(1000, simulate.study(20))
plot(density(p.values_20))
mean(p.values_20 < 0.05) #very likely to detect this effect
plot(density(p.values_0)) # uniform distribution
plot(density(p.values_0), xlim=c(0,1.0)) # uniform distribution
density(p.values_0)
plot(density(p.values_0), xlim=c(0,1.0)) # uniform distribution
abline(v=0.05)
mean(p.values_0 < 0.05) # how often is p.value under 0.05 when there's no effect?
plot(density(p.values_10), xlim=c(0,1.0))
abline(v=0.05)
mean(p.values_10 < 0.05) # somewhat likely to detect this effect
plot(density(p.values_20), xlim=c(0,1.0))
abline(v=0.05)
mean(p.values_20 < 0.05) #very likely to detect this effect
library(data.table)
set.seed(1)
d <- data.table(gender = sample(c("male", "female"),     1000, replace = TRUE),
edu    = sample(c("low", "med", "high"), 1000, replace = TRUE),
bum    = sample(c("bum", "notBum"),      1000, replace = TRUE),
treat  = sample(c("treat", "control"),   1000, replace = TRUE) )
## create headline data
d[ , y := 1 + .5 * I(gender == "female")
+ 5 * I(edu == "high")
+ 2 * I(edu == "med")
+ 0 * I(edu == "low") # same as not including it.
+ 10 * I(treat == "treat")
+ rnorm(.N)
]
## create vector that assigns missingness
## at random, by two groups.
## note, there should be no difference here (because not related to
[bum == "bum",    missing := rbinom(n = .N, size = 1, prob = .8)]
d[bum == "notBum", missing := rbinom(n = .N, size = 1, prob = .2)]
## Full Estimate (hypothetically observed all)
mean(d[treat == "treat", y]) - mean(d[treat == "control", y])
## Naive Estimate (observed values)
mean(d[treat == "treat" & missing == 0, y]) - mean(d[treat == "control" & missing == 0, y])
## Weighted Estimate
summary(lm(y ~ treat, data = d))
d2 = d[missing==0,]
summary(lm(y ~ treat, data = d2))
m2 = lm(y ~ treat, data = d2)
m1 = lm(y ~ treat, data = d)
plot(m1)
plot(m1)
plot(m2)
setwd("~/Downloads/")
d=read.csv("1.csv")
setwd("~/Downloads/")
d=read.csv("1.csv")
d=read.csv("1")
setwd("~/Downloads/")
d=read.csv("1.csv")
setwd("~/Downloads/")
d=read.csv("1.csv")
setwd("~/Desktop/")
d=read.csv("1.csv")
library(reshape)
View(d)
View(d)
d2 = melt(d, id=c("Education"))
View(d2)
View(d2)
write.csv?
;
?write.csv
write.csv(d2, file="2")
flust
flush
setwd("~/Desktop/")
d=read.csv("1.csv")
library(reshape)
d2 = melt(d, id=c("Education"))
write.csv(d2, file="2.csv")
setwd("~/Desktop/")
d=read.csv("1.csv")
library(reshape)
d2 = melt(d, id=c("Education"))
write.csv(d2, file="2.csv")
setwd("~/Desktop/")
d=read.csv("temp.csv")
library(reshape)
d2 = melt(d, id=c("Age Group"))
write.csv(d2, file="2.csv")
View(d)
View(d)
d2 = melt(d, id=c("Age.Group"))
write.csv(d2, file="2.csv")
setwd("~/Desktop/W209_data")
d=read.csv("temp.csv")
library(reshape)
d2 = melt(d, id=c("Age.Group"))
write.csv(d2, file="1.csv")
setwd("~/Desktop/W209_data")
d=read.csv("temp.csv")
library(reshape)
d2 = melt(d, id=c("Age"))
write.csv(d2, file="1.csv")
setwd("~/Desktop/W209_data")
d=read.csv("temp.csv")
library(reshape)
d2 = melt(d, id=c("Education"))
write.csv(d2, file="2.csv")
setwd("~/Desktop/W209_data")
d=read.csv("temp.csv")
library(reshape)
d2 = melt(d, id=c("Income"))
write.csv(d2, file="3.csv")
setwd("~/Desktop/W209_data")
d=read.csv("temp.csv")
library(reshape)
d2 = melt(d, id=c("Income"))
write.csv(d2, file="4.csv")
setwd("~/Desktop/W209_data")
d=read.csv("temp.csv")
library(reshape)
d2 = melt(d, id=c("Race"))
write.csv(d2, file="5.csv")
setwd("~/Desktop/W209_data")
d=read.csv("temp.csv")
View(d)
View(d)
library(reshape)
d2 = melt(d, id=c("Race"))
write.csv(d2, file="5.csv")
setwd("~/Desktop/W209_data")
d=read.csv("temp.csv")
library(reshape)
d2 = melt(d, id=c("year"))
write.csv(d2, file="race_time_trends.csv")
library(lubridate)
d = read.csv("241_Project__Pilot_mTurk.csv", na.strings='')
d <- d[,6:65]
setwd("~/Downloads/")
library(lubridate)
d = read.csv("241_Project__Pilot_mTurk.csv", na.strings='')
d <- d[,6:65]
Questions <- d[1,]
d <- d[2:176,] ##remove 1st row which holds all of the questions
d <- d[as.numeric(ymd_hms(d$V9)-ymd_hms(d$V8)) > 100,] ##Remove datapoints where completion time is too fast
d <- d[,colSums(is.na(d))!=nrow(d)] ##remove columns for where everything is NA
d <- d[,!(substring(colnames(d),0,3) %in% c("Q21", "Q22", "Q25"))] ##Click count Questions
##Re-factor since 1st row was removed
d[,colnames(d)[substring(colnames(d),0,1)=="Q"]] <- lapply(d[,colnames(d)[substring(colnames(d),0,1)=="Q"]] , factor)
likert <- levels(d$Q18_4)
likert_order <- c("Strongly Disagree", "Disagree", "Neither Agree nor Disagree", "Agree", "Strongly Agree")
##Collapse dataframe into single columns for articles and treatment assignment
d$treatment <- ifelse(is.na(d$Q20_7),0,1)
d$art1_1 <- factor(likert[ifelse(is.na(d$Q20_7), d$Q18_4, d$Q20_7)], levels=likert_order)
d$art1_2 <- factor(likert[ifelse(is.na(d$Q20_9), d$Q18_5, d$Q20_9)], levels=likert_order)
d$art2_1 <- factor(likert[ifelse(is.na(d$Q18_6), d$Q19_4, d$Q18_6)], levels=likert_order)
d$art2_2 <- factor(likert[ifelse(is.na(d$Q18_7), d$Q19_5, d$Q18_7)], levels=likert_order)
d$party <- d$Q1
##Assign Independents which party they feel more affiliated to
d$party[d$party=="Independent"] <- d$Q2.1[!is.na(d$Q2.1)]
d$party <- factor(d$party)
d$party_loyalty <- d$Q2
##Assign Independent as Weak affiliation
d$party_loyalty[is.na(d$party_loyalty)] <- "Weak"
d$party_loyalty <- factor(d$party_loyalty, levels=c("Weak", "Moderate", "Strong"))
d_clean <- d[,c("mTurkCode", "Q6_6", "Q6_7", "Q6_8", "Q26", "Q1", "Q2", "Q2.1", "Q19_1", "Q19_2", "Q8", "Q9", "Q15",
"Q16", "Q12", "treatment", "art1_1", "art1_2","art2_1", "art2_2","party","party_loyalty")]
summary(lm(as.numeric(art1_1) ~  party + party_loyalty + party * party_loyalty, data=d_clean))
summary(lm(as.numeric(art1_2) ~  party + treatment + party * treatment, data=d_clean))
summary(lm(as.numeric(art2_1) ~  party + treatment + party * treatment, data=d_clean))
summary(lm(as.numeric(art2_2) ~  party + treatment + party * treatment, data=d_clean))
summary(lm(as.numeric(art1_1) ~   treatment, data=d_clean[d_clean$party == "Republican",]))
summary(lm(as.numeric(art1_1) ~  party_loyalty + treatment, data=d_clean[d_clean$party == "Democrat",]))
summary(lm(as.numeric(art1_2) ~  party_loyalty + treatment, data=d_clean[d_clean$party == "Republican",]))
summary(lm(as.numeric(art1_2) ~  party_loyalty + treatment, data=d_clean[d_clean$party == "Democrat",]))
summary(lm(as.numeric(art2_1) ~  party_loyalty + treatment, data=d_clean[d_clean$party == "Republican",]))
summary(lm(as.numeric(art2_1) ~  party_loyalty + treatment, data=d_clean[d_clean$party == "Democrat",]))
summary(lm(as.numeric(art2_2) ~  party_loyalty + treatment, data=d_clean[d_clean$party == "Republican",]))
summary(lm(as.numeric(art2_2) ~  party_loyalty + treatment, data=d_clean[d_clean$party == "Democrat",]))
View(d_clean)
View(d_clean)
d[d$Q26 == "18-25",]
mean(d[d$Q26 == "18-25",c("Q1")]
;
mean(d[d$Q26 == "18-25",c("Q1")])
mean(d[d$Q26 == "18-25","Q1"])
mean(d[d$Q26 == "18-25",]$Q1)
d[d$Q26 == "18-25",]$Q1
as.numeric(d[d$Q26 == "18-25",]$Q1)
mean(as.numeric(d[d$Q26 == "18-25",]$Q1))
mean(as.numeric(d[d$Q26 == "18-25",]$treatment))
mean(as.numeric(d[d$Q26 == "26-34",]$treatment))
mean(as.numeric(d[d$Q26 == "35-44",]$treatment))
nrow((as.numeric(d[d$Q26 == "35-44",])
;
nrow(d[d$Q26 == "35-44",])
sum(as.numeric(d[d$Q26 == "35-44",]$treatment))
sum(as.numeric(d[d$Q26 == "45-54",]$treatment))
nrow(d[d$Q26 == "45-54",])
setwd("~/Desktop/W209_data")
d=read.csv("temp.csv")
library(reshape)
d2 = melt(d, id=c("year"))
write.csv(d2, file="sex_time_trends.csv")
setwd("~/Desktop/W209_data")
d=read.csv("temp.csv")
library(reshape)
d2 = melt(d, id=c("year"))
write.csv(d2, file="sex_time_trends.csv")
setwd("~/Desktop/W209_data")
d=read.csv("temp.csv")
library(reshape)
d2 = melt(d, id=c("year"))
write.csv(d2, file="sex_time_trends.csv")
